{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9661af56",
   "metadata": {},
   "source": [
    "### 1. Import IMDB-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94cec87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a notebook cell (run once per kernel)\n",
    "import os, sys\n",
    "PROJECT_ROOT = os.path.abspath(\"..\")  # if the notebook is in notebooks/, go up one level\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "from src.load_graph_data import load_hetero_pt, load_imdb\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "\n",
    "data = load_imdb()\n",
    "\n",
    "data = ToUndirected()(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d646cc",
   "metadata": {},
   "source": [
    "### 1.1 Quick sanity check of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04c04d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data loaded ===\n",
      "Metadata (node_types, edge_types):\n",
      "(['movie', 'director', 'actor'], [('movie', 'to', 'director'), ('movie', 'to', 'actor'), ('director', 'to', 'movie'), ('actor', 'to', 'movie'), ('director', 'rev_to', 'movie'), ('actor', 'rev_to', 'movie'), ('movie', 'rev_to', 'director'), ('movie', 'rev_to', 'actor')])\n",
      "\n",
      "Node counts:\n",
      "         movie: 4278\n",
      "      director: 2081\n",
      "         actor: 5257\n",
      "\n",
      "Edge counts:\n",
      "  ('movie', 'to', 'director'): 4278\n",
      "  ('movie', 'to', 'actor'): 12828\n",
      "  ('director', 'to', 'movie'): 4278\n",
      "  ('actor', 'to', 'movie'): 12828\n",
      "  ('director', 'rev_to', 'movie'): 4278\n",
      "  ('actor', 'rev_to', 'movie'): 12828\n",
      "  ('movie', 'rev_to', 'director'): 4278\n",
      "  ('movie', 'rev_to', 'actor'): 12828\n",
      "\n",
      "Feature tensors present?\n",
      "         movie: x present? True, shape=(4278, 3066)\n",
      "      director: x present? True, shape=(2081, 3066)\n",
      "         actor: x present? True, shape=(5257, 3066)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---------- Print a quick summary ----------\n",
    "print(\"=== Data loaded ===\")\n",
    "print(\"Metadata (node_types, edge_types):\")\n",
    "print(data.metadata())  # (['movie','director','actor'], [('movie','to','director'), ...])\n",
    "\n",
    "# Basic counts per node type\n",
    "print(\"\\nNode counts:\")\n",
    "for ntype in data.node_types:\n",
    "    print(f\"  {ntype:>12}: {data[ntype].num_nodes}\")\n",
    "\n",
    "# Basic counts per edge type\n",
    "print(\"\\nEdge counts:\")\n",
    "for et in data.edge_types:\n",
    "    E = data[et].edge_index.size(1)\n",
    "    print(f\"  {et}: {E}\")\n",
    "\n",
    "# Peek at feature availability\n",
    "print(\"\\nFeature tensors present?\")\n",
    "for ntype in data.node_types:\n",
    "    has_x = 'x' in data[ntype]\n",
    "    shape = tuple(data[ntype].x.shape) if has_x else None\n",
    "    print(f\"  {ntype:>12}: x present? {has_x}, shape={shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bef5bf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available()\n",
    "                      else \"mps\" if getattr(torch.backends, \"mps\", None) and torch.backends.mps.is_available()\n",
    "                      else \"cpu\")\n",
    "\n",
    "# Pick any integer seed\n",
    "TORCH_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfea7331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: (['movie', 'director', 'actor'], [('movie', 'to', 'director'), ('movie', 'to', 'actor'), ('director', 'to', 'movie'), ('actor', 'to', 'movie'), ('director', 'rev_to', 'movie'), ('actor', 'rev_to', 'movie'), ('movie', 'rev_to', 'director'), ('movie', 'rev_to', 'actor')])\n",
      "Supervised edge types: [('movie', 'to', 'director'), ('movie', 'to', 'actor'), ('director', 'to', 'movie'), ('actor', 'to', 'movie'), ('director', 'rev_to', 'movie'), ('actor', 'rev_to', 'movie'), ('movie', 'rev_to', 'director'), ('movie', 'rev_to', 'actor')]\n",
      "Build train graph!\n",
      "Build link loaders!\n",
      "Starting training!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_training\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01meval_link\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m collect_scores, topk_eval_with_splits\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m model, predictor, loaders, splits = \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mTORCH_SEED\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprimary_ntype\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmovie\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mneg_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# <— more negatives per positive\u001b[39;49;00m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfanout\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwd\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscore_head\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdot\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# or 'mlp' to try the MLP scorer\u001b[39;49;00m\n\u001b[32m     22\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ITU/Research Project/GNN-Campaign-Detection/core/GNN/src/train.py:94\u001b[39m, in \u001b[36mrun_training\u001b[39m\u001b[34m(DEVICE, TORCH_SEED, data, primary_ntype, hidden, out_dim, layers, dropout, neg_ratio, batch_size, fanout, val_ratio, test_ratio, epochs, lr, wd, score_head)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mStarting training!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, epochs + \u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     tr_loss, tr_acc = \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaders\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m     va_loss, va_acc = eval_epoch(DEVICE, model, predictor, loaders[\u001b[33m'\u001b[39m\u001b[33mval\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m     96\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] train loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtr_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m acc \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtr_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     97\u001b[39m           \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mval loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mva_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m acc \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mva_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ITU/Research Project/GNN-Campaign-Detection/core/GNN/src/train.py:40\u001b[39m, in \u001b[36mtrain_epoch\u001b[39m\u001b[34m(DEVICE, model, predictor, optimizer, loaders_train)\u001b[39m\n\u001b[32m     38\u001b[39m batch = batch.to(DEVICE)\n\u001b[32m     39\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m loss, acc = \u001b[43mbatch_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43met\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m loss.backward()\n\u001b[32m     42\u001b[39m optimizer.step()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ITU/Research Project/GNN-Campaign-Detection/core/GNN/src/train.py:9\u001b[39m, in \u001b[36mbatch_loss\u001b[39m\u001b[34m(model, predictor, batch, edge_type)\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbatch_loss\u001b[39m(model, predictor, batch, edge_type):\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     h_dict = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     e_store = batch[edge_type]\n\u001b[32m     11\u001b[39m     idx = e_store.edge_label_index    \u001b[38;5;66;03m# [2, B_total] (positives + negatives)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv-pyg/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv-pyg/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/ITU/Research Project/GNN-Campaign-Detection/core/GNN/src/model.py:36\u001b[39m, in \u001b[36mHeteroSAGE.forward\u001b[39m\u001b[34m(self, x_dict, edge_index_dict)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x_dict, edge_index_dict):\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv-pyg/lib/python3.12/site-packages/torch/fx/graph_module.py:738\u001b[39m, in \u001b[36mGraphModule.recompile.<locals>.call_wrapped\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    737\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_wrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m738\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wrapped_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv-pyg/lib/python3.12/site-packages/torch/fx/graph_module.py:303\u001b[39m, in \u001b[36m_WrappedCall.__call__\u001b[39m\u001b[34m(self, obj, *args, **kwargs)\u001b[39m\n\u001b[32m    301\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.cls_call(obj, *args, **kwargs)\n\u001b[32m    302\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m303\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    305\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m e.__traceback__\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv-pyg/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv-pyg/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<eval_with_key>.1:18\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(self, x, edge_index)\u001b[39m\n\u001b[32m     16\u001b[39m edge_index__movie__rev_to__director = edge_index_dict.get((\u001b[33m'\u001b[39m\u001b[33mmovie\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mrev_to\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdirector\u001b[39m\u001b[33m'\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     17\u001b[39m edge_index__movie__rev_to__actor = edge_index_dict.get((\u001b[33m'\u001b[39m\u001b[33mmovie\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mrev_to\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mactor\u001b[39m\u001b[33m'\u001b[39m), \u001b[38;5;28;01mNone\u001b[39;00m);  edge_index_dict = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m layers_0__director1 = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m0\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmovie__to__director\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx__movie\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx__director\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index__movie__to__director\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m layers_0__actor1 = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.layers, \u001b[33m\"\u001b[39m\u001b[33m0\u001b[39m\u001b[33m\"\u001b[39m).movie__to__actor((x__movie, x__actor), edge_index__movie__to__actor)\n\u001b[32m     20\u001b[39m layers_0__movie1 = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.layers, \u001b[33m\"\u001b[39m\u001b[33m0\u001b[39m\u001b[33m\"\u001b[39m).director__to__movie((x__director, x__movie), edge_index__director__to__movie)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv-pyg/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv-pyg/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv-pyg/lib/python3.12/site-packages/torch_geometric/nn/conv/sage_conv.py:135\u001b[39m, in \u001b[36mSAGEConv.forward\u001b[39m\u001b[34m(self, x, edge_index, size)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;66;03m# propagate_type: (x: OptPairTensor)\u001b[39;00m\n\u001b[32m    134\u001b[39m out = \u001b[38;5;28mself\u001b[39m.propagate(edge_index, x=x, size=size)\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlin_l\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m x_r = x[\u001b[32m1\u001b[39m]\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.root_weight \u001b[38;5;129;01mand\u001b[39;00m x_r \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv-pyg/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1551\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1552\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv-pyg/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1557\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1558\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1559\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1560\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1561\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1562\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1564\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1565\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv-pyg/lib/python3.12/site-packages/torch_geometric/nn/dense/linear.py:127\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) -> Tensor:\n\u001b[32m    122\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Forward pass.\u001b[39;00m\n\u001b[32m    123\u001b[39m \n\u001b[32m    124\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    125\u001b[39m \u001b[33;03m        x (torch.Tensor): The input features.\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m127\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Train again with stronger negatives; keep your fanout as before\n",
    "import os, sys\n",
    "PROJECT_ROOT = os.path.abspath(\"..\")  # if notebook is in notebooks/\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "from src.train import run_training\n",
    "from src.eval_link import collect_scores, topk_eval_with_splits\n",
    "\n",
    "\n",
    "\n",
    "model, predictor, loaders, splits = run_training(\n",
    "    DEVICE,\n",
    "    TORCH_SEED,\n",
    "    data,\n",
    "    primary_ntype='movie',\n",
    "    hidden=128, out_dim=128, layers=2, dropout=0.1,\n",
    "    neg_ratio=3.0,                # <— more negatives per positive\n",
    "    batch_size=1024, fanout=[15, 10],\n",
    "    val_ratio=0.1, test_ratio=0.1, epochs=10, lr=1e-3, wd=1e-4,\n",
    "    score_head='dot'              # or 'mlp' to try the MLP scorer\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f511e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07714a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUROC/AP (as before)\n",
    "scores = collect_scores(DEVICE, model, predictor, loaders['test'])\n",
    "print(\"TEST AUROC/AP per relation:\")\n",
    "for et, s in scores.items():\n",
    "    print(et, s)\n",
    "\n",
    "# Recall@K with cosine and larger K (easier for many-to-many like movie→actor)\n",
    "res_k50_cos = topk_eval_with_splits(model, splits, splits['sup_ets'], K=50, use_dot=False)\n",
    "print(\"\\nRecall@50 (cosine) per relation:\")\n",
    "for et, m in res_k50_cos.items():\n",
    "    print(et, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e53b4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram (held-out vs random) — pick one relation\n",
    "import matplotlib.pyplot as plt, torch\n",
    "h_train = embed_with_graph(model, splits['train_graph'])\n",
    "et = ('movie','to','director')\n",
    "S = h_train[et[0]]; D = h_train[et[2]]\n",
    "pos = splits['test_pos'][et]\n",
    "pos_scores = (S[pos[0]] * D[pos[1]]).sum(dim=1).cpu().numpy()\n",
    "g = torch.Generator().manual_seed(0)\n",
    "neg_src = torch.randint(0, S.size(0), (len(pos_scores),), generator=g)\n",
    "neg_dst = torch.randint(0, D.size(0), (len(pos_scores),), generator=g)\n",
    "neg_scores = (S[neg_src] * D[neg_dst]).sum(dim=1).cpu().numpy()\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.hist(pos_scores, bins=50, alpha=0.6, label='Held-out positives')\n",
    "plt.hist(neg_scores, bins=50, alpha=0.6, label='Random negatives')\n",
    "plt.title(f\"Score distributions for {et}\"); plt.legend(); plt.show()\n",
    "\n",
    "# Qualitative Top-K (choose a source that *has* held-out positives)\n",
    "sources_with_pos = splits['test_pos'][et][0].unique()\n",
    "src_id = int(sources_with_pos[1])  # pick first valid movie\n",
    "top_ids, top_scores = topk_for_source(h_train, et, src_id, K=20, cosine=True)\n",
    "true_dests = set(splits['test_pos'][et][1][splits['test_pos'][et][0]==src_id].cpu().tolist())\n",
    "print(\"movie_id:\", src_id)\n",
    "print(\"Top-20 actor ids:\", top_ids)\n",
    "print(\"Is held-out true?:\", [i in true_dests for i in top_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a795de52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Light suggestions: recall curves, cosine vs dot, qualitative Top-K, optional fine-tune ===\n",
    "import torch, matplotlib.pyplot as plt\n",
    "\n",
    "# --- 1) Recall@K curves (cosine) ---\n",
    "K_list = [10, 20, 50, 100]\n",
    "h_train = embed_with_graph(model, splits['train_graph'])  # leakage-safe embeddings\n",
    "ets = splits['sup_ets']\n",
    "\n",
    "recall_curves = {et: [] for et in ets}\n",
    "for et in ets:\n",
    "    for K in K_list:\n",
    "        res = recall_at_k_mrr(h_train, et, splits['test_pos'][et], K=K, use_dot=False)\n",
    "        recall_curves[et].append(res['recall@K'])\n",
    "\n",
    "# Plot curves\n",
    "plt.figure(figsize=(7,5))\n",
    "for et, vals in recall_curves.items():\n",
    "    label = f\"{et[0]}→{et[2]}\"\n",
    "    plt.plot(K_list, vals, marker='o', label=label)\n",
    "plt.xlabel(\"K\"); plt.ylabel(\"Recall@K\"); plt.title(\"Recall@K (cosine) per relation\"); plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# --- 2) Dot vs Cosine table at K=50 ---\n",
    "def recall_at_k_for_metric(h, et, K, use_dot):\n",
    "    return recall_at_k_mrr(h, et, splits['test_pos'][et], K=K, use_dot=use_dot)['recall@K']\n",
    "\n",
    "print(\"\\nRecall@50: dot vs cosine\")\n",
    "for et in ets:\n",
    "    r_dot = recall_at_k_for_metric(h_train, et, K=50, use_dot=True)\n",
    "    r_cos = recall_at_k_for_metric(h_train, et, K=50, use_dot=False)\n",
    "    print(f\"{et}: dot={r_dot:.3f} | cosine={r_cos:.3f}\")\n",
    "\n",
    "# --- 3) Qualitative Top-K (pick a source that has held-out positives) ---\n",
    "et_demo = ('movie','to','actor')  # change if you want a different relation\n",
    "srcs_with_pos = splits['test_pos'][et_demo][0].unique()\n",
    "if len(srcs_with_pos) > 0:\n",
    "    src_id = int(srcs_with_pos[0])  # first valid source\n",
    "    top_ids, top_scores = topk_for_source(h_train, et_demo, src_id, K=20, cosine=True)\n",
    "    true_dests = set(splits['test_pos'][et_demo][1][splits['test_pos'][et_demo][0]==src_id].cpu().tolist())\n",
    "    print(f\"\\nQualitative Top-20 for source {et_demo[0]} id={src_id} (cosine):\")\n",
    "    print(\"Top-20 dest ids:\", top_ids)\n",
    "    print(\"Is held-out true?:\", [i in true_dests for i in top_ids])\n",
    "else:\n",
    "    print(f\"No sources with held-out positives found for {et_demo}\")\n",
    "\n",
    "# --- 4) (Optional) Fine-tune a bit more, then re-run the same checks ---\n",
    "# Uncomment to do 2 more epochs with same loaders/optimizer settings:\n",
    "# opt = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "# for e in range(2):\n",
    "#     tr_loss, tr_acc = train_epoch(model, predictor, opt, loaders['train'])\n",
    "#     va_loss, va_acc = eval_epoch(model, predictor, loaders['val'])\n",
    "#     print(f\"[Finetune {e+1}/2] train {tr_loss:.4f}/{tr_acc:.3f} | val {va_loss:.4f}/{va_acc:.3f}\")\n",
    "# # Recompute embeddings & recall curves if you fine-tuned:\n",
    "# # h_train = embed_with_graph(model, splits['train_graph'])\n",
    "# # (then rerun the recall curve and Top-K blocks above)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72335494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Export embeddings for the primary node type (e.g., 'movie') ---\n",
    "\n",
    "\n",
    "# Use the splits you already have (leakage-safe train_graph)\n",
    "z = export_embeddings(model, splits['train_graph'], primary_ntype='movie', layers=2, batch_size=4096)\n",
    "\n",
    "# L2-normalize (cosine-friendly)\n",
    "z = torch.nn.functional.normalize(z, p=2, dim=1)  # [N, d]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce026820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_graph_cosine(z, k=30, chunk=8192):\n",
    "    \"\"\"\n",
    "    Returns (indices, sims), where:\n",
    "      indices: [N, k] int64 neighbor IDs (excluding self)\n",
    "      sims:    [N, k] float32 cosine sims corresponding to indices\n",
    "    \"\"\"\n",
    "    z = torch.nn.functional.normalize(z, p=2, dim=1)\n",
    "    N, d = z.shape\n",
    "    all_idx = []\n",
    "    all_sim = []\n",
    "    for start in range(0, N, chunk):\n",
    "        end = min(start+chunk, N)\n",
    "        block = z[start:end]                               # [B, d]\n",
    "        sims = block @ z.T                                 # [B, N]\n",
    "        sims[:, start:end] = -1.0                          # exclude self-range; will be masked out by topk anyway\n",
    "        vals, idx = torch.topk(sims, k=k, dim=1)           # [B, k]\n",
    "        all_idx.append(idx.cpu())\n",
    "        all_sim.append(vals.cpu())\n",
    "    return torch.vstack(all_idx), torch.vstack(all_sim)\n",
    "\n",
    "knn_idx, knn_sim = knn_graph_cosine(z, k=30)  # typical k=15~50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c48746",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install hdbscan (once)\n",
    "import numpy as np\n",
    "try:\n",
    "    import hdbscan\n",
    "except ImportError:\n",
    "    raise RuntimeError(\"Please `pip install hdbscan` to use HDBSCAN.\")\n",
    "\n",
    "def cluster_hdbscan(z, min_cluster_size=15, min_samples=None, metric='euclidean'):\n",
    "    # HDBSCAN works in distance space; use euclidean on normalized z (cosine≈euclid on unit vectors)\n",
    "    Z = z.numpy() if isinstance(z, torch.Tensor) else z\n",
    "    clf = hdbscan.HDBSCAN(min_cluster_size=min_cluster_size, min_samples=min_samples, metric=metric)\n",
    "    labels = clf.fit_predict(Z)    # -1 are noise points\n",
    "    probs  = clf.probabilities_\n",
    "    return labels, probs, clf\n",
    "\n",
    "labels_hdb, probs_hdb, hdb = cluster_hdbscan(z, min_cluster_size=20, min_samples=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc352ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install igraph leidenalg\n",
    "import igraph as ig\n",
    "import leidenalg as la\n",
    "\n",
    "def leiden_from_knn(knn_idx, knn_sim=None, resolution=1.0, weighted=True):\n",
    "    \"\"\"\n",
    "    Build an undirected graph from kNN edges and run Leiden.\n",
    "    \"\"\"\n",
    "    N = knn_idx.shape[0]\n",
    "    # Build edge list (i < j to avoid duplicates)\n",
    "    src = np.repeat(np.arange(N), knn_idx.shape[1])\n",
    "    dst = knn_idx.reshape(-1)\n",
    "    edge_pairs = np.stack([src, dst], axis=1)\n",
    "    # Make undirected unique edges\n",
    "    edge_pairs = np.sort(edge_pairs, axis=1)\n",
    "    edge_pairs = np.unique(edge_pairs, axis=0)\n",
    "    g = ig.Graph(n=N, edges=edge_pairs.tolist(), directed=False)\n",
    "\n",
    "    weights = None\n",
    "    if weighted and knn_sim is not None:\n",
    "        # Map weights per edge; we take max of (i->j, j->i) if duplicates happened before unique\n",
    "        sim_map = {}\n",
    "        for i in range(N):\n",
    "            for k, j in enumerate(knn_idx[i]):\n",
    "                a, b = (i, int(j))\n",
    "                key = (min(a,b), max(a,b))\n",
    "                w = float(knn_sim[i, k])\n",
    "                sim_map[key] = max(sim_map.get(key, -1e9), w)\n",
    "        weights = [sim_map[(a,b)] for a,b in edge_pairs]\n",
    "\n",
    "    part = la.find_partition(g, la.RBConfigurationVertexPartition, weights=weights, resolution_parameter=resolution)\n",
    "    return np.array(part.membership), g, part\n",
    "\n",
    "labels_lei, g_lei, part_lei = leiden_from_knn(knn_idx.numpy(), knn_sim.numpy(), resolution=1.0, weighted=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910bcb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
    "\n",
    "def intrinsic_metrics(z, labels, max_points=20000):\n",
    "    # ignore noise label -1 for silhouette if present\n",
    "    z_np = z.numpy() if isinstance(z, torch.Tensor) else z\n",
    "    idx = np.arange(len(labels))\n",
    "    mask = labels != -1\n",
    "    use = idx[mask]\n",
    "    if len(use) < 2 or len(np.unique(labels[mask])) < 2:\n",
    "        return {'silhouette': np.nan, 'calinski_harabasz': np.nan, 'davies_bouldin': np.nan}\n",
    "    # downsample for speed\n",
    "    if len(use) > max_points:\n",
    "        use = np.random.RandomState(0).choice(use, size=max_points, replace=False)\n",
    "    s = silhouette_score(z_np[use], labels[use], metric='euclidean')\n",
    "    ch = calinski_harabasz_score(z_np[use], labels[use])\n",
    "    db = davies_bouldin_score(z_np[use], labels[use])\n",
    "    return {'silhouette': float(s), 'calinski_harabasz': float(ch), 'davies_bouldin': float(db)}\n",
    "\n",
    "m_in_hdb = intrinsic_metrics(z, labels_hdb)\n",
    "m_in_lei = intrinsic_metrics(z, labels_lei)\n",
    "print(\"HDBSCAN intrinsic:\", m_in_hdb)\n",
    "print(\"Leiden   intrinsic:\", m_in_lei)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff53b050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_purity_movie_director(labels, data, primary_ntype='movie'):\n",
    "    \"\"\"\n",
    "    For each movie, get its directors. For each cluster, take the majority director and compute purity.\n",
    "    Returns micro- and macro-averaged purity (exclude noise cluster -1).\n",
    "    \"\"\"\n",
    "    ei = data[('movie','to','director')].edge_index  # [2, E]\n",
    "    m, d = ei[0].cpu().numpy(), ei[1].cpu().numpy()\n",
    "    N = data[primary_ntype].num_nodes\n",
    "    labels = np.asarray(labels)\n",
    "    # build directors-per-movie lists\n",
    "    from collections import defaultdict, Counter\n",
    "    dirs_by_movie = defaultdict(list)\n",
    "    for mi, di in zip(m, d):\n",
    "        dirs_by_movie[int(mi)].append(int(di))\n",
    "    # per-cluster majority director\n",
    "    cluster_to_movies = {}\n",
    "    for mi in range(N):\n",
    "        c = int(labels[mi])\n",
    "        if c == -1:   # skip noise\n",
    "            continue\n",
    "        cluster_to_movies.setdefault(c, []).append(mi)\n",
    "    if not cluster_to_movies:\n",
    "        return {'micro_purity': np.nan, 'macro_purity': np.nan, 'n_clusters': 0}\n",
    "\n",
    "    purities = []\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for c, movies in cluster_to_movies.items():\n",
    "        # count directors across all movies in cluster\n",
    "        cnt = Counter()\n",
    "        for mi in movies:\n",
    "            cnt.update(dirs_by_movie.get(mi, []))\n",
    "        if len(cnt) == 0:\n",
    "            purities.append(0.0)\n",
    "            continue\n",
    "        maj_dir, maj_count = cnt.most_common(1)[0]\n",
    "        # total assignments = number of (movie, director) pairs in cluster\n",
    "        cluster_total = sum(cnt.values())\n",
    "        purities.append(maj_count / cluster_total)\n",
    "        total += cluster_total\n",
    "        correct += maj_count\n",
    "    micro = correct / total if total > 0 else np.nan\n",
    "    macro = float(np.mean(purities)) if purities else np.nan\n",
    "    return {'micro_purity': micro, 'macro_purity': macro, 'n_clusters': len(cluster_to_movies)}\n",
    "\n",
    "pur_hdb = cluster_purity_movie_director(labels_hdb, data, 'movie')\n",
    "pur_lei = cluster_purity_movie_director(labels_lei, data, 'movie')\n",
    "print(\"HDBSCAN movie→director purity:\", pur_hdb)\n",
    "print(\"Leiden   movie→director purity:\", pur_lei)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7131f3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install scikit-learn (usually present)\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "\n",
    "def stability_ari_nmi(z, cluster_fn, n_runs=3):\n",
    "    parts = []\n",
    "    for s in range(n_runs):\n",
    "        np.random.seed(42 + s)\n",
    "        torch.manual_seed(42 + s)\n",
    "        labels, *_ = cluster_fn()\n",
    "        parts.append(np.asarray(labels))\n",
    "    # pairwise ARI/NMI\n",
    "    aris, nmis = [], []\n",
    "    for i in range(n_runs):\n",
    "        for j in range(i+1, n_runs):\n",
    "            aris.append(adjusted_rand_score(parts[i], parts[j]))\n",
    "            nmis.append(normalized_mutual_info_score(parts[i], parts[j]))\n",
    "    return {'ARI_mean': float(np.mean(aris)), 'NMI_mean': float(np.mean(nmis))}\n",
    "\n",
    "# Example: HDBSCAN stability over different min_samples\n",
    "stab_hdb = stability_ari_nmi(\n",
    "    z,\n",
    "    cluster_fn=lambda: cluster_hdbscan(z, min_cluster_size=20, min_samples=np.random.randint(5, 15)),\n",
    "    n_runs=3\n",
    ")\n",
    "print(\"HDBSCAN stability:\", stab_hdb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1d6c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install umap-learn\n",
    "import umap\n",
    "def umap_embed(z, n_neighbors=30, min_dist=0.1, random_state=42):\n",
    "    Z = z.numpy() if isinstance(z, torch.Tensor) else z\n",
    "    reducer = umap.UMAP(n_neighbors=n_neighbors, min_dist=min_dist, random_state=random_state)\n",
    "    return reducer.fit_transform(Z)  # [N, 2]\n",
    "\n",
    "um = umap_embed(z, n_neighbors=30, min_dist=0.05)\n",
    "# Plot with your favorite tool; color by labels_hdb or labels_lei\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.scatter(um[:,0], um[:,1], c=labels_hdb, s=5, cmap='tab20', alpha=0.9)\n",
    "plt.title(\"UMAP of movie embeddings — HDBSCAN clusters\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7eeeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Export embeddings (leakage-safe) and normalize\n",
    "z = export_embeddings(model, splits['train_graph'], primary_ntype='movie', layers=2, batch_size=4096)\n",
    "z = torch.nn.functional.normalize(z, p=2, dim=1)\n",
    "\n",
    "# 2) k-NN graph\n",
    "knn_idx, knn_sim = knn_graph_cosine(z, k=30)\n",
    "\n",
    "# 3) Clustering\n",
    "labels_hdb, probs_hdb, _ = cluster_hdbscan(z, min_cluster_size=20, min_samples=10)\n",
    "labels_lei, g_lei, part_lei = leiden_from_knn(knn_idx.numpy(), knn_sim.numpy(), resolution=1.0, weighted=True)\n",
    "\n",
    "# 4) Metrics\n",
    "print(\"Intrinsic (HDBSCAN):\", intrinsic_metrics(z, labels_hdb))\n",
    "print(\"Intrinsic (Leiden):  \", intrinsic_metrics(z, labels_lei))\n",
    "print(\"Purity (movie→director, HDBSCAN):\", cluster_purity_movie_director(labels_hdb, data))\n",
    "print(\"Purity (movie→director, Leiden): \", cluster_purity_movie_director(labels_lei, data))\n",
    "\n",
    "# 5) Stability (optional)\n",
    "stab_hdb = stability_ari_nmi(z, lambda: cluster_hdbscan(z, 20, np.random.randint(5, 15)), n_runs=3)\n",
    "print(\"HDBSCAN stability:\", stab_hdb)\n",
    "\n",
    "# 6) UMAP (optional)\n",
    "um = umap_embed(z, n_neighbors=30, min_dist=0.05)\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.scatter(um[:,0], um[:,1], c=labels_hdb, s=5, cmap='tab20', alpha=0.9)\n",
    "plt.title(\"UMAP of movie embeddings — HDBSCAN clusters\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn (MPS)",
   "language": "python",
   "name": "gnn-mps"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
