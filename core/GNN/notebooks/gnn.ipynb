{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9661af56",
   "metadata": {},
   "source": [
    "### 1. Import e-mail data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "94cec87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In a notebook cell (run once per kernel)\n",
    "import os, sys\n",
    "PROJECT_ROOT = os.path.abspath(\"..\")  # if the notebook is in notebooks/, go up one level\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "from src.load_graph_data import load_hetero_pt, load_imdb\n",
    "from torch_geometric.transforms import ToUndirected\n",
    "\n",
    "data = load_hetero_pt()\n",
    "\n",
    "data = ToUndirected()(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d646cc",
   "metadata": {},
   "source": [
    "### 1.1 Only keep certain nodes for training purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "315e7135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Per-relation connectivity ===\n",
      "\n",
      "Relation: ('email', 'has_url', 'url')  (|E|=21790)\n",
      "  src[email]  deg0=16524, deg1=8814 ( 30.0% ), deg>=2=4061 ( 13.8% ), total=29399\n",
      "  dst[url]  deg0=0, deg1=11065 ( 80.6% ), deg>=2=2669 ( 19.4% ), total=13734\n",
      "\n",
      "Relation: ('url', 'has_domain', 'domain')  (|E|=13730)\n",
      "  src[url]  deg0=4, deg1=13730 ( 100.0% ), deg>=2=0 ( 0.0% ), total=13734\n",
      "  dst[domain]  deg0=0, deg1=5248 ( 80.3% ), deg>=2=1285 ( 19.7% ), total=6533\n",
      "\n",
      "Relation: ('url', 'has_stem', 'stem')  (|E|=13730)\n",
      "  src[url]  deg0=4, deg1=13730 ( 100.0% ), deg>=2=0 ( 0.0% ), total=13734\n",
      "  dst[stem]  deg0=0, deg1=7248 ( 97.7% ), deg>=2=174 ( 2.3% ), total=7422\n",
      "\n",
      "Relation: ('url', 'rev_has_url', 'email')  (|E|=21790)\n",
      "  src[url]  deg0=0, deg1=11065 ( 80.6% ), deg>=2=2669 ( 19.4% ), total=13734\n",
      "  dst[email]  deg0=16524, deg1=8814 ( 30.0% ), deg>=2=4061 ( 13.8% ), total=29399\n",
      "\n",
      "Relation: ('domain', 'rev_has_domain', 'url')  (|E|=13730)\n",
      "  src[domain]  deg0=0, deg1=5248 ( 80.3% ), deg>=2=1285 ( 19.7% ), total=6533\n",
      "  dst[url]  deg0=4, deg1=13730 ( 100.0% ), deg>=2=0 ( 0.0% ), total=13734\n",
      "\n",
      "Relation: ('stem', 'rev_has_stem', 'url')  (|E|=13730)\n",
      "  src[stem]  deg0=0, deg1=7248 ( 97.7% ), deg>=2=174 ( 2.3% ), total=7422\n",
      "  dst[url]  deg0=4, deg1=13730 ( 100.0% ), deg>=2=0 ( 0.0% ), total=13734\n",
      "\n",
      "=== Node degrees aggregated across all relations ===\n",
      "  email: deg0=16524, deg1=0 ( 0.0% ), deg>=2=12875 ( 43.8% ), total=29399\n",
      "  url: deg0=0, deg1=0 ( 0.0% ), deg>=2=13734 ( 100.0% ), total=13734\n",
      "  domain: deg0=0, deg1=0 ( 0.0% ), deg>=2=6533 ( 100.0% ), total=6533\n",
      "  stem: deg0=0, deg1=0 ( 0.0% ), deg>=2=7422 ( 100.0% ), total=7422\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ROOT = os.path.abspath(\"..\")  # if notebook is in notebooks/\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "from src.graph_diagnostics import print_connectivity_report\n",
    "\n",
    "# Which node types do we want to KEEP in the graph?\n",
    "keep = ['email', 'url', 'domain', 'stem']   # <- adjust as you like\n",
    "\n",
    "keep_set = set(keep)\n",
    "\n",
    "# 1) Delete node types that are NOT in keep\n",
    "for ntype in list(data.node_types):   # list(...) so we can modify while iterating\n",
    "    if ntype not in keep_set:\n",
    "        del data[ntype]\n",
    "\n",
    "# 2) Delete edge types whose src or dst is NOT in keep\n",
    "for et in list(data.edge_types):      # et is (src, rel, dst)\n",
    "    src, rel, dst = et\n",
    "    if src not in keep_set or dst not in keep_set:\n",
    "        del data[et]\n",
    "\n",
    "print_connectivity_report(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec21df2",
   "metadata": {},
   "source": [
    "### 1.2 Normalization of node-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ac34ce22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization is now handled in the graph builder (core.graph.normalizer.normalize_graph)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0942a92f",
   "metadata": {},
   "source": [
    "### 1.3 Quick sanity check of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f41d414c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data loaded ===\n",
      "Metadata (node_types, edge_types):\n",
      "(['email', 'url', 'domain', 'stem'], [('email', 'has_url', 'url'), ('url', 'has_domain', 'domain'), ('url', 'has_stem', 'stem'), ('url', 'rev_has_url', 'email'), ('domain', 'rev_has_domain', 'url'), ('stem', 'rev_has_stem', 'url')])\n",
      "\n",
      "Node counts:\n",
      "         email: 29399\n",
      "           url: 13734\n",
      "        domain: 6533\n",
      "          stem: 7422\n",
      "\n",
      "Edge counts:\n",
      "  ('email', 'has_url', 'url'): 21790\n",
      "  ('url', 'has_domain', 'domain'): 13730\n",
      "  ('url', 'has_stem', 'stem'): 13730\n",
      "  ('url', 'rev_has_url', 'email'): 21790\n",
      "  ('domain', 'rev_has_domain', 'url'): 13730\n",
      "  ('stem', 'rev_has_stem', 'url'): 13730\n",
      "\n",
      "Feature tensors present?\n",
      "         email: x present? True, shape=(29399, 388)\n",
      "           url: x present? True, shape=(13734, 2)\n",
      "        domain: x present? True, shape=(6533, 10)\n",
      "          stem: x present? True, shape=(7422, 10)\n"
     ]
    }
   ],
   "source": [
    "# ---------- Print a quick summary ----------\n",
    "print(\"=== Data loaded ===\")\n",
    "print(\"Metadata (node_types, edge_types):\")\n",
    "print(data.metadata())  # (['movie','director','actor'], [('movie','to','director'), ...])\n",
    "\n",
    "# Basic counts per node type\n",
    "print(\"\\nNode counts:\")\n",
    "for ntype in data.node_types:\n",
    "    print(f\"  {ntype:>12}: {data[ntype].num_nodes}\")\n",
    "\n",
    "# Basic counts per edge type\n",
    "print(\"\\nEdge counts:\")\n",
    "for et in data.edge_types:\n",
    "    E = data[et].edge_index.size(1)\n",
    "    print(f\"  {et}: {E}\")\n",
    "\n",
    "# Peek at feature availability\n",
    "print(\"\\nFeature tensors present?\")\n",
    "for ntype in data.node_types:\n",
    "    has_x = 'x' in data[ntype]\n",
    "    shape = tuple(data[ntype].x.shape) if has_x else None\n",
    "    print(f\"  {ntype:>12}: x present? {has_x}, shape={shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17af6b4",
   "metadata": {},
   "source": [
    "### 1.5 Setting device and torch seed (so training and eval can be replicated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bef5bf4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Prefer CUDA; otherwise use CPU to avoid MPS CSR limitations in neighbor sampling\n",
    "DEVICE = \"mps\"\n",
    "print(DEVICE)\n",
    "# Pick any integer seed\n",
    "TORCH_SEED = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "715224af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "PRIMARY_NTYPE = 'email'\n",
    "HIDDEN_DIM = 128\n",
    "OUT_DIM = 128\n",
    "LAYERS = 2\n",
    "DROPOUT = 0.1\n",
    "NEG_RATIO = 1.0\n",
    "BATCH_SIZE = 512\n",
    "FANOUT = [2, 1]  # 2-hop\n",
    "VAL_RATIO = 0.1\n",
    "TEST_RATIO = 0.1\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 5e-4\n",
    "WEIGHT_DECAY = 5e-4\n",
    "SCORE_HEAD = 'dot'\n",
    "MODEL_SAVE_NAME = 'best_model.pt'\n",
    "EARLY_STOPPING_PATIENCE = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dfea7331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: (['email', 'url', 'domain', 'stem'], [('email', 'has_url', 'url'), ('url', 'has_domain', 'domain'), ('url', 'has_stem', 'stem'), ('url', 'rev_has_url', 'email'), ('domain', 'rev_has_domain', 'url'), ('stem', 'rev_has_stem', 'url')])\n",
      "Supervised edge types: [('email', 'has_url', 'url'), ('url', 'rev_has_url', 'email')]\n",
      "Build train graph!\n",
      "Build link loaders!\n",
      "Starting training!\n",
      "[Epoch 01] train loss 22.1326 acc 0.833 | val loss 6.7401 acc 0.794\n",
      "✓ Model saved to /Users/mcandersyo/ITU/Research Project/GNN-Campaign-Detection/core/GNN/models/best_model.pt\n",
      "[Epoch 02] train loss 9.3399 acc 0.911 | val loss 3.6949 acc 0.850\n",
      "✓ Model saved to /Users/mcandersyo/ITU/Research Project/GNN-Campaign-Detection/core/GNN/models/best_model.pt\n",
      "[Epoch 03] train loss 3.5897 acc 0.927 | val loss 3.7557 acc 0.856\n",
      "[Epoch 04] train loss 4.9075 acc 0.934 | val loss 6.2889 acc 0.796\n",
      "[Epoch 05] train loss 3.0666 acc 0.938 | val loss 2.7411 acc 0.867\n",
      "✓ Model saved to /Users/mcandersyo/ITU/Research Project/GNN-Campaign-Detection/core/GNN/models/best_model.pt\n",
      "[Epoch 06] train loss 1.5918 acc 0.952 | val loss 1.7803 acc 0.869\n",
      "✓ Model saved to /Users/mcandersyo/ITU/Research Project/GNN-Campaign-Detection/core/GNN/models/best_model.pt\n",
      "[Epoch 07] train loss 1.4191 acc 0.954 | val loss 2.4918 acc 0.871\n",
      "[Epoch 08] train loss 1.4717 acc 0.957 | val loss 1.7620 acc 0.871\n",
      "✓ Model saved to /Users/mcandersyo/ITU/Research Project/GNN-Campaign-Detection/core/GNN/models/best_model.pt\n",
      "[Epoch 09] train loss 1.8629 acc 0.957 | val loss 2.7652 acc 0.878\n",
      "[Epoch 10] train loss 1.2981 acc 0.959 | val loss 1.4233 acc 0.868\n",
      "✓ Model saved to /Users/mcandersyo/ITU/Research Project/GNN-Campaign-Detection/core/GNN/models/best_model.pt\n",
      "[Epoch 11] train loss 1.0182 acc 0.964 | val loss 2.7406 acc 0.871\n",
      "[Epoch 12] train loss 0.8703 acc 0.968 | val loss 1.7487 acc 0.904\n",
      "[Epoch 13] train loss 0.6635 acc 0.970 | val loss 1.7508 acc 0.866\n",
      "[Epoch 14] train loss 1.1602 acc 0.968 | val loss 1.8297 acc 0.892\n",
      "[Epoch 15] train loss 1.7733 acc 0.965 | val loss 5.8207 acc 0.835\n",
      "\n",
      "Early stopping triggered after 15 epochs without val loss improvement.\n",
      "[Test] loss 6.3391 acc 0.832\n"
     ]
    }
   ],
   "source": [
    "# Train again with stronger negatives; keep your fanout as before\n",
    "import os, sys\n",
    "PROJECT_ROOT = os.path.abspath(\"..\")  # if notebook is in notebooks/\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "from src.train import run_training\n",
    "from src.eval_link import collect_scores, topk_eval_with_splits\n",
    "\n",
    "\n",
    "model, predictor, loaders, splits = run_training(\n",
    "    DEVICE,\n",
    "    TORCH_SEED,\n",
    "    data,\n",
    "    primary_ntype=PRIMARY_NTYPE,\n",
    "    hidden=HIDDEN_DIM, out_dim=OUT_DIM, layers=LAYERS, dropout=DROPOUT,\n",
    "    neg_ratio=NEG_RATIO,\n",
    "    batch_size=BATCH_SIZE, fanout=FANOUT,     # 2-hop\n",
    "    val_ratio=VAL_RATIO, test_ratio=TEST_RATIO, epochs=EPOCHS, lr=LEARNING_RATE, wd=WEIGHT_DECAY,\n",
    "    score_head=SCORE_HEAD,\n",
    "    model_save_name=MODEL_SAVE_NAME,\n",
    "    early_stopping_patience=EARLY_STOPPING_PATIENCE,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf85fe5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mcandersyo/ITU/Research Project/GNN-Campaign-Detection/core/GNN/src/model_io.py:118: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(load_path, map_location=device)\n",
      "/Users/mcandersyo/ITU/Research Project/GNN-Campaign-Detection/core/GNN/src/model_io.py:180: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(get_models_dir() / filename, map_location=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint ready from epoch 5 with val loss 0.5770\n",
      "Metadata: (['email', 'sender', 'url'], [('email', 'has_sender', 'sender'), ('email', 'has_url', 'url'), ('sender', 'rev_has_sender', 'email'), ('url', 'rev_has_url', 'email')])\n",
      "Resuming from epoch 5 (best val 0.5770) using checkpoint 'best_model.pt'\n",
      "Starting training!\n",
      "[Epoch 06] train loss 0.5849 acc 0.962 | val loss 0.5195 acc 0.882\n",
      "✓ Model saved to /Users/mcandersyo/ITU/Research Project/GNN-Campaign-Detection/core/GNN/models/best_model.pt\n",
      "[Epoch 07] train loss 0.7713 acc 0.965 | val loss 0.8037 acc 0.880\n",
      "[Epoch 08] train loss 0.2400 acc 0.966 | val loss 0.4832 acc 0.896\n",
      "✓ Model saved to /Users/mcandersyo/ITU/Research Project/GNN-Campaign-Detection/core/GNN/models/best_model.pt\n",
      "[Epoch 09] train loss 0.4104 acc 0.970 | val loss 0.5190 acc 0.909\n",
      "[Epoch 10] train loss 0.2990 acc 0.970 | val loss 0.3417 acc 0.916\n",
      "✓ Model saved to /Users/mcandersyo/ITU/Research Project/GNN-Campaign-Detection/core/GNN/models/best_model.pt\n",
      "[Epoch 11] train loss 0.2704 acc 0.973 | val loss 0.3516 acc 0.923\n",
      "[Epoch 12] train loss 0.4444 acc 0.974 | val loss 0.8925 acc 0.922\n",
      "[Epoch 13] train loss 0.3943 acc 0.973 | val loss 0.5199 acc 0.922\n",
      "[Epoch 14] train loss 0.3851 acc 0.975 | val loss 0.3164 acc 0.919\n",
      "✓ Model saved to /Users/mcandersyo/ITU/Research Project/GNN-Campaign-Detection/core/GNN/models/best_model.pt\n",
      "[Epoch 15] train loss 0.2772 acc 0.977 | val loss 0.2880 acc 0.929\n",
      "✓ Model saved to /Users/mcandersyo/ITU/Research Project/GNN-Campaign-Detection/core/GNN/models/best_model.pt\n",
      "[Epoch 16] train loss 0.1832 acc 0.976 | val loss 0.3402 acc 0.935\n",
      "[Epoch 17] train loss 0.2734 acc 0.978 | val loss 0.3975 acc 0.928\n",
      "[Epoch 18] train loss 0.2738 acc 0.978 | val loss 0.6418 acc 0.920\n",
      "[Epoch 19] train loss 0.3280 acc 0.978 | val loss 0.7667 acc 0.916\n",
      "[Epoch 20] train loss 0.3181 acc 0.979 | val loss 0.4261 acc 0.925\n",
      "\n",
      "Early stopping triggered after 20 epochs without val loss improvement.\n",
      "[Test] loss 0.8449 acc 0.923\n"
     ]
    }
   ],
   "source": [
    "# Resume training from a saved checkpoint\n",
    "\n",
    "import os, sys\n",
    "PROJECT_ROOT = os.path.abspath(\"..\")  # if notebook is in notebooks/\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "from src.train import run_training\n",
    "from src.model_io import load_model_checkpoint\n",
    "\n",
    "# Optional: check what's saved\n",
    "model_ckpt, predictor_ckpt, checkpoint = load_model_checkpoint(\n",
    "    DEVICE, metadata=data.metadata(), filename=MODEL_SAVE_NAME\n",
    ")\n",
    "print(f\"Checkpoint ready from epoch {checkpoint['epoch']} with val loss {checkpoint['val_loss']:.4f}\")\n",
    "\n",
    "# Continue training; set epochs to total target (not just extra)\n",
    "model, predictor, loaders, splits = run_training(\n",
    "    DEVICE,\n",
    "    TORCH_SEED,\n",
    "    data,\n",
    "    primary_ntype=PRIMARY_NTYPE,\n",
    "    hidden=HIDDEN_DIM, out_dim=OUT_DIM, layers=LAYERS, dropout=DROPOUT,\n",
    "    neg_ratio=NEG_RATIO,\n",
    "    batch_size=BATCH_SIZE, fanout=FANOUT,\n",
    "    val_ratio=VAL_RATIO, test_ratio=TEST_RATIO, epochs=20, lr=LEARNING_RATE, wd=WEIGHT_DECAY,\n",
    "    score_head=SCORE_HEAD,\n",
    "    model_save_name=MODEL_SAVE_NAME,\n",
    "    early_stopping_patience=EARLY_STOPPING_PATIENCE,\n",
    "    resume_from=MODEL_SAVE_NAME,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn (MPS)",
   "language": "python",
   "name": "gnn-mps"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
